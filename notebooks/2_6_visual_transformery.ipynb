{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Pokroƒçil√© techniky a modely v detekci objekt≈Ø\n",
    "\n",
    "1. üìö P≈ôehled dal≈°√≠ch model≈Ø\n",
    "üî∑ Vizu√°ln√≠ transformery (ViT ‚Äì Vision Transformers)\n",
    "\n",
    "- Zalo≈æeny na architektu≈ôe transformer≈Ø zn√°m√© z NLP.\n",
    "- M√≠sto konvoluc√≠ rozdƒõluj√≠ obr√°zek na ‚Äûpatches‚Äú a zpracov√°vaj√≠ je jako sekvenci.\n",
    "- *V√Ωhoda*: l√©pe zachycuj√≠ glob√°ln√≠ kontext.\n",
    "- *Nev√Ωhoda*: n√°roƒçnƒõj≈°√≠ na data a v√Ωpoƒçetn√≠ v√Ωkon.\n",
    "\n",
    "*P≈ô√≠klady*:\n",
    "- ViT (Google) ‚Äì z√°kladn√≠ transformer pro obr√°zky.\n",
    "- DETR (Facebook) ‚Äì transformer pro detekci objekt≈Ø.\n",
    "- Swin Transformer ‚Äì hierarchick√Ω transformer s posuvn√Ωmi okny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. üîÅ Transfer learning a fine-tuning\n",
    "\n",
    "#### üß© Co to je?\n",
    "- Transfer learning: vyu≈æit√≠ p≈ôedtr√©novan√©ho modelu na nov√© √∫loze.\n",
    "- Fine-tuning: doladƒõn√≠ modelu na nov√©m datasetu.\n",
    "\n",
    "‚úÖ *V√Ωhody*:\n",
    "- Rychlej≈°√≠ tr√©nink.\n",
    "- Vy≈°≈°√≠ p≈ôesnost na mal√Ωch datasetech.\n",
    "- M√©nƒõ v√Ωpoƒçetnƒõ n√°roƒçn√©.\n",
    "\n",
    "üß™ Uk√°zka v PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "# Naƒçten√≠ p≈ôedtr√©novan√©ho modelu\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Nahrazen√≠ v√Ωstupn√≠ vrstvy pro 3 t≈ô√≠dy\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. üîó Kombinace model≈Ø\n",
    "\n",
    "##### üß† P≈ô√≠klad: Detekce + Klasifikace\n",
    "- Detekƒçn√≠ model (nap≈ô. YOLO) najde objekty.\n",
    "- Klasifikaƒçn√≠ model (nap≈ô. ResNet) urƒç√≠ podtyp objektu.\n",
    "\n",
    "üîÑ Postup:\n",
    "- Detekuj objekty (bounding boxy).\n",
    "- O≈ô√≠zni objekty z obr√°zku.\n",
    "- Po≈°li je do klasifik√°toru.\n",
    "\n",
    "üß™ Uk√°zka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# V√Ωstup z detekce: bbox = [x1, y1, x2, y2]\n",
    "cropped = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "# P≈ôedzpracov√°n√≠ pro klasifik√°tor\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "input_tensor = transform(cropped).unsqueeze(0)\n",
    "\n",
    "# Inference klasifik√°toru\n",
    "output = classifier(input_tensor)\n",
    "predicted_class = output.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v√Ωukov√Ω skript pro tr√©nink a inference modelu DETR (Facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib\n",
    "!git clone https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Uk√°zka anotace ve form√°tu COCO\n",
    "\n",
    "{\n",
    "  \"images\": [\n",
    "    {\"id\": 1, \"file_name\": \"image1.jpg\", \"width\": 640, \"height\": 480}\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\"id\": 1, \"image_id\": 1, \"category_id\": 1, \"bbox\": [100, 150, 200, 200], \"area\": 40000, \"iscrowd\": 0}\n",
    "  ],\n",
    "  \"categories\": [\n",
    "    {\"id\": 1, \"name\": \"object\"}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tr√©ninkov√Ω skript (zjednodu≈°en√Ω)\n",
    "\n",
    "from detr.models.detr import build_detr\n",
    "from detr.datasets.coco import make_coco_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Dataset a transformace\n",
    "transform = make_coco_transforms('train')\n",
    "dataset = CustomCocoDataset('annotations.json', 'images/', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# Model\n",
    "model = build_detr(num_classes=2)  # 1 t≈ô√≠da + background\n",
    "model.to('cuda')\n",
    "\n",
    "# Tr√©nink\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for images, targets in dataloader:\n",
    "        images = [img.to('cuda') for img in images]\n",
    "        targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# skript pro Inferenci\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Naƒçten√≠ modelu\n",
    "model.eval()\n",
    "img = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "transform = T.Compose([T.Resize(800), T.ToTensor()])\n",
    "img_tensor = transform(img).unsqueeze(0).to('cuda')\n",
    "\n",
    "# Inference\n",
    "outputs = model(img_tensor)\n",
    "probs = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "boxes = outputs['pred_boxes'][0]\n",
    "\n",
    "# Filtrace\n",
    "keep = probs.max(-1).values > 0.7\n",
    "boxes = boxes[keep]\n",
    "\n",
    "# Zobrazen√≠\n",
    "def plot_results(pil_img, boxes):\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x, y, w, h = box\n",
    "        ax.add_patch(plt.Rectangle((x, y), w, h, fill=False, color='red', linewidth=2))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_results(img, boxes.cpu())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
