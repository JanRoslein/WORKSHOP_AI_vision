{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† 1. Detekce objekt≈Ø pomoc√≠ DETR (Visual Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Naƒçten√≠ modelu DETR\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model.eval()\n",
    "\n",
    "# Naƒçten√≠ obr√°zku\n",
    "def load_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Inference a vykreslen√≠\n",
    "def detect_objects(image):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        if score > 0.7:\n",
    "            box = [round(i, 2) for i in box.tolist()]\n",
    "            draw.rectangle(box, outline=\"red\", width=2)\n",
    "            draw.text((box[0], box[1]), f\"{model.config.id2label[label.item()]}: {round(score.item(), 2)}\", fill=\"red\")\n",
    "    image.show()\n",
    "\n",
    "# Uk√°zka\n",
    "img_url = \"https://ultralytics.com/images/zidane.jpg\"\n",
    "image = load_image(img_url)\n",
    "detect_objects(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë∂ 2. Odhad vƒõku z obliƒçeje pomoc√≠ modelu z Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "# Get example image from official fairface repo + read it in as an image\n",
    "r = requests.get('https://github.com/dchen236/FairFace/blob/master/detected_faces/race_Asian_face0.jpg?raw=true')\n",
    "im = Image.open(BytesIO(r.content))\n",
    "\n",
    "# Init model, transforms\n",
    "model = ViTForImageClassification.from_pretrained('nateraw/vit-age-classifier')\n",
    "transforms = ViTFeatureExtractor.from_pretrained('nateraw/vit-age-classifier')\n",
    "\n",
    "# Transform our image and pass it through the model\n",
    "inputs = transforms(im, return_tensors='pt')\n",
    "output = model(**inputs)\n",
    "\n",
    "# Predicted Class probabilities\n",
    "proba = output.logits.softmax(1)\n",
    "\n",
    "# Predicted Classes\n",
    "preds = proba.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Model: MKgoud/License-Plate-Recognizer\n",
    "- Architektura: YOLOv8m (pojede i na uboh√© GPU s 3GB vRAM)\n",
    "- √öloha: Detekce a o≈ôez registraƒçn√≠ch znaƒçek z obr√°zk≈Ø vozidel\n",
    "- Form√°t: .pt model kompatibiln√≠ s knihovnou ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Naƒçten√≠ modelu z lok√°ln√≠ho souboru nebo Hugging Face - morsetechlab/yolov11-license-plate-detection\n",
    "model = YOLO('yolov11x-license-plate.pt')\n",
    "\n",
    "# Naƒçten√≠ obr√°zku z URL nebo lok√°lnƒõ\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/3/3f/French_vehicle_license_plate.jpg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Inference\n",
    "results = model(image)\n",
    "\n",
    "# Zobrazen√≠ v√Ωsledk≈Ø\n",
    "results.print()\n",
    "results.show()  # zobraz√≠ obr√°zek s bounding boxy\n",
    "\n",
    "# Ulo≈æen√≠ v√Ωsledku\n",
    "results.save()  # ulo≈æ√≠ do runs/detect/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ 3. Vlastn√≠ naƒç√≠t√°n√≠ obr√°zk≈Ø a p≈ô√≠prava tensoru (bez knihoven typu ImageProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Parametry pro normalizaci (nap≈ô. ImageNet)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Funkce pro naƒçten√≠ a zpracov√°n√≠ obr√°zku\n",
    "def load_and_preprocess_image(path, size=(224, 224)):\n",
    "    # 1. Naƒçten√≠ obr√°zku\n",
    "    image = Image.open(path).convert(\"RGB\")  # p≈ôevod na RGB\n",
    "\n",
    "    # 2. Zmƒõna velikosti\n",
    "    image = image.resize(size)\n",
    "\n",
    "    # 3. P≈ôevod na NumPy pole a normalizace do rozsahu [0, 1]\n",
    "    image_np = np.array(image).astype(np.float32) / 255.0\n",
    "\n",
    "    # 4. P≈ôeskl√°d√°n√≠ dimenz√≠ (HWC ‚Üí CHW)\n",
    "    image_np = image_np.transpose((2, 0, 1))\n",
    "\n",
    "    # 5. Normalizace podle mean a std\n",
    "    for i in range(3):\n",
    "        image_np[i] = (image_np[i] - mean[i]) / std[i]\n",
    "\n",
    "    # 6. P≈ôevod na PyTorch tensor a p≈ôid√°n√≠ batch dimenze\n",
    "    image_tensor = torch.tensor(image_np).unsqueeze(0)\n",
    "\n",
    "    return image_tensor\n",
    "\n",
    "# Uk√°zka pou≈æit√≠\n",
    "image_path = \"data/fotka.jpg\"  # nahraƒè vlastn√≠ cestou\n",
    "tensor = load_and_preprocess_image(image_path)\n",
    "print(\"Tensor shape:\", tensor.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
