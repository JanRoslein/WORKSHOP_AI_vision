{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Optimalizace v√Ωkonu model≈Ø\n",
    "\n",
    "Optimalizace v√Ωkonu je kl√≠ƒçov√° pro nasazen√≠ model≈Ø v re√°ln√©m ƒçase, zejm√©na na za≈ô√≠zen√≠ch s omezen√Ωmi v√Ωpoƒçetn√≠mi zdroji (mobil, edge, embedded). Mezi hlavn√≠ techniky pat≈ô√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßÆ 1. Kvantizace (Quantization)\n",
    "Kvantizace p≈ôev√°d√≠ v√°hy a/nebo aktivace modelu z v√Ωchoz√≠ho form√°tu (nap≈ô. float32) na men≈°√≠ ƒç√≠seln√© reprezentace (int8, float16, bfloat16), ƒç√≠m≈æ:\n",
    "\n",
    "- sni≈æuje velikost modelu,\n",
    "- zrychluje inference,\n",
    "- sni≈æuje spot≈ôebu pamƒõti a energie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Typy kvantizace:**\n",
    "\n",
    "- *Post-training*: Kvantizace po tr√©ninku, bez nutnosti dal≈°√≠ho uƒçen√≠.\n",
    "- *Quantization-aware training (QAT)*: Model se uƒç√≠ s kvantizaƒçn√≠mi efekty bƒõhem tr√©ninku.\n",
    "- *Dynamic quantization*: Kvantizace vah, aktivace se kvantizuj√≠ za bƒõhu.\n",
    "- *Static quantization*: Kvantizace vah i aktivac√≠, vy≈æaduje kalibraƒçn√≠ data.\n",
    "\n",
    "- *float32*: 32 bit≈Ø - velmi p≈ôesn√©, ale extr√©mnƒõ n√°roƒçn√©\n",
    "- *float16*: rychlej≈°√≠, st≈ôednƒõ p≈ôesn√©\n",
    "- *bfloat16*: pro modely nejpou≈æ√≠vanƒõj≈°√≠, st≈ôednƒõ p≈ôesn√©, exponent ƒç√≠sla je v FP32, um√≠ grafiky s j√°drem Pascal a vy≈°≈°√≠ (p≈ôibli≈ænƒõ od roku 2016)\n",
    "- *int8*: velmi rychl√Ω, mal√Ω model, vhodn√© pro mobiln√≠ za≈ô√≠zen√≠, edge ap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Uk√°zkov√Ω k√≥d: Post-training kvantizace v PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# 1. Naƒçten√≠ p≈ôedtr√©novan√©ho modelu\n",
    "model_fp32 = resnet18(pretrained=True)\n",
    "model_fp32.eval()\n",
    "\n",
    "# 2. Aplikace dynamick√© kvantizace\n",
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model_fp32,  # model\n",
    "    {torch.nn.Linear},  # vrstvy k kvantizaci\n",
    "    dtype=torch.qint8  # c√≠lov√Ω form√°t\n",
    ")\n",
    "\n",
    "# 3. Ulo≈æen√≠ kvantizovan√©ho modelu\n",
    "torch.save(model_int8.state_dict(), \"resnet18_int8.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÇÔ∏è 2. Pruning (pro≈ôez√°v√°n√≠) - jen pro AI experty ...\n",
    "\n",
    "Odstra≈àuje m√©nƒõ d≈Øle≈æit√© v√°hy nebo cel√© kan√°ly neuronov√© s√≠tƒõ.\n",
    "\n",
    "*Unstructured pruning* ‚Äì odstra≈àuje jednotliv√© v√°hy.\n",
    "*Structured pruning* ‚Äì odstra≈àuje cel√© filtry nebo vrstvy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "prune.l1_unstructured(model.layer1[0].conv1, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ 3. Batch inferencing\n",
    "\n",
    "Zpracov√°n√≠ v√≠ce vstup≈Ø najednou (nap≈ô. 8 obr√°zk≈Ø m√≠sto 1) zvy≈°uje efektivitu inference na GPU.\n",
    "\n",
    "- pokud m√°te dostatek vRAM/RAM tak d√°vky obr√°zk≈Ø jsou nezbytnost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# vstupn√≠ batch: [batch_size, channels, height, width]\n",
    "batch_input = torch.stack([img1, img2, img3, img4])\n",
    "output = model(batch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üß† Pokroƒçil√© kvantizaƒçn√≠ p≈ô√≠stupy\n",
    "\n",
    "Modern√≠ frameworky (nap≈ô. Intel Neural Compressor, NVIDIA TensorRT, OpenVINO) umo≈æ≈àuj√≠:\n",
    "\n",
    "- per-layer kvantizaci ‚Äì r≈Øzn√© vrstvy maj√≠ r≈Øzn√© form√°ty (nap≈ô. int8 pro konvoluce, fp16 pro dense vrstvy),\n",
    "- per-channel kvantizaci ‚Äì ka≈æd√©mu kan√°lu je p≈ôi≈ôazena vlastn√≠ kvantizaƒçn√≠ ≈°k√°la,\n",
    "- mixed precision ‚Äì kombinace fp16, bf16, int8 podle v√Ωznamu vrstvy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
