{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Validace a export modelu\n",
    "#### üß™ 1. Vyhodnocen√≠ modelu na testovac√≠ch datech\n",
    "\n",
    "Po dokonƒçen√≠ tr√©ninku je d≈Øle≈æit√© model otestovat na nez√°visl√©m testovac√≠m datasetu - takov√° data, kter√° model bƒõhem tr√©ninku je≈°tƒõ nevidƒõl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python val.py \\\n",
    "  --weights runs/train/yolov12_nano_custom/weights/best.pt \\\n",
    "  --data data/custom_data.yaml \\\n",
    "  --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tento p≈ô√≠kaz vyp√≠≈°e metriky jako:\n",
    "\n",
    "- *Precision, Recall, mAP@0.5, mAP@0.5:0.95*\n",
    "- Poƒçet detekovan√Ωch objekt≈Ø\n",
    "- Chyby podle t≈ô√≠d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ 2. Export modelu\n",
    "\n",
    "Model lze exportovat do r≈Øzn√Ωch form√°t≈Ø pro nasazen√≠:\n",
    "\n",
    "- PyTorch (**.pt**) ‚Äì v√Ωchoz√≠ form√°t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ONNX** (Open Neural Network Exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export.py \\\n",
    "  --weights runs/train/yolov12_nano_custom/weights/best.pt \\\n",
    "  --include onnx \\\n",
    "  --img 640 \\\n",
    "  --dynamic\n",
    "\n",
    "# V√Ωstup: best.onnx ‚Äì vhodn√© pro nasazen√≠ v prost≈ôed√≠ch jako TensorRT, OpenVINO, ONNX Runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CoreML, TensorRT, OpenVINO, TF SavedModel, TFLite, TF.js\n",
    "\n",
    "Tyto form√°ty lze exportovat pomoc√≠ --include s odpov√≠daj√≠c√≠ volbou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ 3. P≈ô√≠prava na nasazen√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py \\\n",
    "  --weights best.pt \\\n",
    "  --img 640 \\\n",
    "  --source path/to/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Optimalizace v√Ωkonu:*\n",
    "Pou≈æij **ONNX** + TensorRT pro rychl√© inference na GPU.\n",
    "Pou≈æij TFLite pro mobiln√≠ za≈ô√≠zen√≠.\n",
    "Pou≈æij TorchScript pro embedded za≈ô√≠zen√≠.\n",
    "\n",
    "- *Integrace do aplikace:*\n",
    "**REST API** (nap≈ô. FastAPI, Flask)\n",
    "Desktop (nap≈ô. PyQt, Electron)\n",
    "Mobiln√≠ aplikace (TensorFlow Lite, CoreML)\n",
    "Web (TensorFlow.js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uk√°zka jednoduch√© inference:\n",
    "\n",
    "#### ‚úÖ Co pot≈ôebuje≈°:\n",
    "- onnxruntime\n",
    "- opencv-python\n",
    "- ONNX model (best.onnx)\n",
    "- Testovac√≠ obr√°zek (test.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Cesta k ONNX modelu a vstupn√≠mu obr√°zku\n",
    "model_path = \"best.onnx\"\n",
    "image_path = \"test.jpg\"\n",
    "\n",
    "# Naƒçten√≠ obr√°zku a p≈ôedzpracov√°n√≠\n",
    "img = cv2.imread(image_path)\n",
    "img_resized = cv2.resize(img, (640, 640))\n",
    "img_input = img_resized[:, :, ::-1].transpose(2, 0, 1)  # BGR ‚Üí RGB ‚Üí CHW\n",
    "img_input = np.expand_dims(img_input, axis=0).astype(np.float32) / 255.0\n",
    "\n",
    "# Inicializace ONNX runtime\n",
    "session = ort.InferenceSession(model_path)\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "# Inference\n",
    "start = time.time()\n",
    "outputs = session.run(None, {input_name: img_input})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Inference time: {end - start:.3f} s\")\n",
    "\n",
    "# Zpracov√°n√≠ v√Ωstupu\n",
    "predictions = outputs[0][0]  # [num_detections, 6] ‚Üí [x1, y1, x2, y2, conf, class]\n",
    "\n",
    "# Filtrace podle confidence threshold\n",
    "conf_threshold = 0.25\n",
    "for det in predictions:\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    if conf > conf_threshold:\n",
    "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"{int(cls)} {conf:.2f}\", (int(x1), int(y1) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Zobrazen√≠ v√Ωsledku\n",
    "cv2.imshow(\"Detekce\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
